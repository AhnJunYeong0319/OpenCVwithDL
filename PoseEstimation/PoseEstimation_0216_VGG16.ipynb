{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021.02.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-Use VGG16, but also gonna try with ResNets & VGGNets (template prepared) ++ R-CNN**   \n",
    "**-Normalization should be added**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style = \"background-color : red\">Color Test</span></h3><br>\n",
    "    - <strong>Using AlexNet</strong><br>\n",
    "    - <strong>Using color image data</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Alert!</h3>\n",
    "- <strong><u>If lr (Learning Rate) is small and decay is big</u>,<br>1) val_loss easily converges to 0 and<br>2) learning ends so fast that ACC never gets better (0.5, 1, asf.. - extreme value)<strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hewas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8194      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4320 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "4320/4320 [==============================] - 73s 17ms/sample - loss: 0.2939 - acc: 0.9222 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "4320/4320 [==============================] - 66s 15ms/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "4320/4320 [==============================] - 67s 15ms/sample - loss: 0.0028 - acc: 0.9998 - val_loss: 4.8345e-04 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "4320/4320 [==============================] - 67s 16ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 2.0720e-04 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "4320/4320 [==============================] - 67s 16ms/sample - loss: 5.2492e-04 - acc: 1.0000 - val_loss: 1.2289e-04 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "4320/4320 [==============================] - 67s 15ms/sample - loss: 3.9175e-04 - acc: 1.0000 - val_loss: 7.6429e-05 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "4320/4320 [==============================] - 66s 15ms/sample - loss: 2.7739e-04 - acc: 1.0000 - val_loss: 4.9764e-05 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "4320/4320 [==============================] - 67s 15ms/sample - loss: 1.8281e-04 - acc: 1.0000 - val_loss: 3.5606e-05 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "4320/4320 [==============================] - 68s 16ms/sample - loss: 1.6031e-04 - acc: 1.0000 - val_loss: 2.5827e-05 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "4320/4320 [==============================] - 67s 15ms/sample - loss: 9.2259e-05 - acc: 1.0000 - val_loss: 1.9073e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e96478a948>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "c_F = pickle.load(open(\"color_train_F.pickle\", \"rb\"))\n",
    "c_T = pickle.load(open(\"color_train_T.pickle\", \"rb\"))\n",
    "\n",
    "\n",
    "x = np.concatenate( (c_F, c_T), axis = 0 )\n",
    "\n",
    "\n",
    "y = [1 for i in range(len(c_F))] + [0 for i in range(len(c_T))]\n",
    "\n",
    "X = []\n",
    "\n",
    "for rows in x:\n",
    "    tmp = cv2.resize(rows, (224, 224))\n",
    "    X.append(tmp)\n",
    "    \n",
    "X = np.array(X)\n",
    "X = X.reshape(-1, 224, 224, 3)\n",
    "y = np.array(y)\n",
    "\n",
    "nums = [i for i in range(4800)]\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(4)\n",
    "random.shuffle(nums)\n",
    "\n",
    "X = X[nums]\n",
    "y = y[nums]\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add( Conv2D(input_shape= INPUT_SHAPE, filters=64, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add( Conv2D(filters=64, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add( Conv2D(filters=128, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add( Conv2D(filters=128, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 6th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 7th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 8th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 9th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 10th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 11th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 12th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 13th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "########################## Passing it to a Fully Connected layer ##########################\n",
    "model.add( Flatten() )\n",
    "\n",
    "K = INPUT_SHAPE[0] * INPUT_SHAPE[1] * INPUT_SHAPE[2]\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "model.add( Dense(4096, input_shape=( K, )) )\n",
    "model.add( Activation('relu') )\n",
    "# Add Dropout\n",
    "model.add( Dropout(0.4) )\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add( Dense(4096) )\n",
    "model.add( Activation('relu') )\n",
    "# Add Dropout\n",
    "model.add( Dropout(0.4) )\n",
    "\n",
    "# Output Layer\n",
    "model.add( Dense(2) )\n",
    "model.add( Activation('softmax') )\n",
    "          \n",
    "opt = tf.keras.optimizers.Adam(lr = 1e-6)\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", # or binary_crossentropy\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, y, batch_size = 32, epochs = 10, validation_split = 0.1)  # batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style = \"background-color : gray\">Gray (<span style = \"background-color : red\">from Color</span>) Test</span></h3><br>\n",
    "    - <strong>Using AlexNet</strong><br>\n",
    "    - <strong>Using gray-scale image data</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "c_F = pickle.load(open(\"color_train_F.pickle\", \"rb\"))\n",
    "c_T = pickle.load(open(\"color_train_T.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change color into gray & resize from color images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = []\n",
    "for i in range(c_F.shape[0]):\n",
    "    F.append(cv2.resize( cv2.cvtColor(c_F[i], cv2.COLOR_BGR2GRAY), (224, 224) ))\n",
    "\n",
    "T = []\n",
    "for j in range(c_T.shape[0]):\n",
    "    T.append(cv2.resize( cv2.cvtColor(c_T[i], cv2.COLOR_BGR2GRAY), (224, 224) ))\n",
    "    \n",
    "F, T = np.array(F), np.array(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate( (F, T), axis = 0 )\n",
    "X = X.reshape(-1, 224, 224, 1)\n",
    "\n",
    "y = [1 for i in range(len(F))] + [0 for i in range(len(T))]\n",
    "y = np.array(y)\n",
    "\n",
    "nums = [i for i in range(c_F.shape[0] + c_T.shape[0])]\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(4)\n",
    "random.shuffle(nums)\n",
    "\n",
    "X = X[nums]\n",
    "y = y[nums]\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.8)\n",
    "sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_options))\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add( Conv2D(input_shape= INPUT_SHAPE, filters=64, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add( Conv2D(filters=64, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add( Conv2D(filters=128, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add( Conv2D(filters=128, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 6th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 7th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 8th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 9th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 10th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 11th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 12th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 13th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "########################## Passing it to a Fully Connected layer ##########################\n",
    "model.add( Flatten() )\n",
    "\n",
    "K = INPUT_SHAPE[0] * INPUT_SHAPE[1] * INPUT_SHAPE[2]\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "model.add( Dense(4096, input_shape=( K, )) )\n",
    "model.add( Activation('relu') )\n",
    "# Add Dropout\n",
    "model.add( Dropout(0.4) )\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add( Dense(4096) )\n",
    "model.add( Activation('relu') )\n",
    "# Add Dropout\n",
    "model.add( Dropout(0.4) )\n",
    "\n",
    "# Output Layer\n",
    "model.add( Dense(2) )\n",
    "model.add( Activation('softmax') )\n",
    "          \n",
    "opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", # or binary_crossentropy\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, y, batch_size = 8, epochs = 10, validation_split = 0.1)  # batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch doesn't work well?\n",
    "Refer to this; https://stackoverflow.com/questions/37213388/keras-accuracy-does-not-change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
