{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021.02.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-Use VGG16, but also gonna try with ResNets**   \n",
    "**-Normalization added!**   \n",
    "**-<span style = \"background-color : pink\">The last test for train data</span>**\n",
    "\n",
    "..Grayscale worked well as muas as color did!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style = \"background-color : red\">Color Test</span></h3><br>\n",
    "    - <strong>Using VGG16</strong><br>\n",
    "    - <strong>Using color image data</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Alert!</h3>\n",
    "- <strong><u>If lr (Learning Rate) is small and decay is big</u>,<br>1) val_loss easily converges to 0 and<br>2) learning ends so fast that ACC never gets better (0.5, 1, asf.. - extreme value)<strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <span style = \"background-color : skyblue\">At Desk </span></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "c_F = pickle.load(open(\"imagedata/Desk/color_train2_F.pickle\", \"rb\"))\n",
    "c_T = pickle.load(open(\"imagedata/Desk/color_train2_T.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate( (c_F, c_T), axis = 0 )\n",
    "\n",
    "\n",
    "y = [1 for i in range(len(c_F))] + [0 for i in range(len(c_T))]\n",
    "\n",
    "X = []\n",
    "\n",
    "for rows in x:\n",
    "    tmp = cv2.resize(rows, (224, 224))\n",
    "    X.append(tmp)\n",
    "    \n",
    "X = np.array(X)\n",
    "X = X.reshape(-1, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.8)\n",
    "sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization\n",
    "X = X / 255.0\n",
    "\n",
    "y = np.array(y)\n",
    "\n",
    "nums = [i for i in range(8000)]\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(4)\n",
    "random.shuffle(nums)\n",
    "\n",
    "X = X[nums]\n",
    "y = y[nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hewas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2002      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 62,380,346\n",
      "Trainable params: 62,380,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 44s 6ms/sample - loss: 0.3551 - acc: 0.8996 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 34s 5ms/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 7.2959e-05 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 35s 5ms/sample - loss: 5.1997e-04 - acc: 1.0000 - val_loss: 1.2485e-05 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 36s 5ms/sample - loss: 1.8876e-04 - acc: 1.0000 - val_loss: 3.8494e-06 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 33s 5ms/sample - loss: 8.9084e-05 - acc: 1.0000 - val_loss: 1.1925e-06 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 34s 5ms/sample - loss: 6.0198e-05 - acc: 1.0000 - val_loss: 6.0394e-07 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 33s 5ms/sample - loss: 2.5514e-05 - acc: 1.0000 - val_loss: 1.8075e-07 - val_acc: 1.0000: 2s - ETA: 0s - loss: 2.5596e-05 - acc: 1.\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 34s 5ms/sample - loss: 1.5324e-05 - acc: 1.0000 - val_loss: 9.0748e-08 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 33s 5ms/sample - loss: 9.4759e-06 - acc: 1.0000 - val_loss: 2.7269e-08 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 33s 5ms/sample - loss: 7.3984e-06 - acc: 1.0000 - val_loss: 6.7055e-09 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a60e20e488>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add( Conv2D(input_shape= INPUT_SHAPE, filters=64, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add( Conv2D(filters=64, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add( Conv2D(filters=128, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add( Conv2D(filters=128, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 6th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 7th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 8th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 9th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 10th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 11th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 12th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 13th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "########################## Passing it to a Fully Connected layer ##########################\n",
    "model.add( Flatten() )\n",
    "\n",
    "K = INPUT_SHAPE[0] * INPUT_SHAPE[1] * INPUT_SHAPE[2]\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "model.add( Dense(4096, input_shape=( K, )) )\n",
    "model.add( Activation('relu') )\n",
    "# Add Dropout\n",
    "model.add( Dropout(0.4) )\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add( Dense(4096) )\n",
    "model.add( Activation('relu') )\n",
    "# Add Dropout\n",
    "model.add( Dropout(0.4) )\n",
    "\n",
    "# Output Layer\n",
    "model.add( Dense(2) )\n",
    "model.add( Activation('softmax') )\n",
    "          \n",
    "opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", # or binary_crossentropy\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, y, batch_size = 8, epochs = 10, validation_split = 0.1)  # batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"0217_alexnet.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Test Data Pre-processing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_F = pickle.load(open(\"imagedata/Desk/color_test2_F.pickle\", \"rb\"))\n",
    "test_T = pickle.load(open(\"imagedata/Desk/color_test2_T.pickle\", \"rb\"))\n",
    "\n",
    "test_x = np.concatenate( (test_F, test_T), axis = 0 )\n",
    "\n",
    "\n",
    "test_y = [1 for i in range(len(test_F))] + [0 for i in range(len(test_T))]\n",
    "\n",
    "test_X = []\n",
    "\n",
    "for rows in test_x:\n",
    "    tmp = cv2.resize(rows, (224, 224))\n",
    "    test_X.append(tmp)\n",
    "    \n",
    "test_X = np.array(test_X)\n",
    "test_X = test_X.reshape(-1, 224, 224, 3)\n",
    "\n",
    "test_X = test_X / 255.0\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "nums = [i for i in range(2000)]\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(6)\n",
    "random.shuffle(nums)\n",
    "\n",
    "test_X = test_X[nums]\n",
    "test_y = test_y[nums]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 4s 2ms/sample - loss: 7.1526e-09 - acc: 1.0000 1s - loss: 7.748 - ETA: 0s - loss: 7.4876e-09 \n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_X, test_y, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.152555408396211e-09, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did I code properly?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 719\n",
    "\n",
    "predictions = model.predict([test_X[k].reshape(1, 224, 224, 3)])\n",
    "print(np.argmax(predictions[0]))\n",
    "\n",
    "cv2.imshow(\"title\", test_X[k])\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style = \"background-color : gray\">Gray (<span style = \"background-color : red\">from Color</span>) Test</span></h3><br>\n",
    "    - <strong>Using VGG16</strong><br>\n",
    "    - <strong>Using gray-scale image data</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "c_F = pickle.load(open(\"color_train_F.pickle\", \"rb\"))\n",
    "c_T = pickle.load(open(\"color_train_T.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change color into gray & resize from color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = []\n",
    "for i in range(c_F.shape[0]):\n",
    "    F.append(cv2.resize( cv2.cvtColor(c_F[i], cv2.COLOR_BGR2GRAY), (224, 224) ))\n",
    "\n",
    "T = []\n",
    "for j in range(c_T.shape[0]):\n",
    "    T.append(cv2.resize( cv2.cvtColor(c_T[i], cv2.COLOR_BGR2GRAY), (224, 224) ))\n",
    "    \n",
    "F, T = np.array(F), np.array(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate( (F, T), axis = 0 )\n",
    "X = X.reshape(-1, 224, 224, 1)\n",
    "\n",
    "y = [1 for i in range(len(F))] + [0 for i in range(len(T))]\n",
    "y = np.array(y)\n",
    "\n",
    "nums = [i for i in range(c_F.shape[0] + c_T.shape[0])]\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(4)\n",
    "random.shuffle(nums)\n",
    "\n",
    "X = X[nums]\n",
    "y = y[nums]\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.8)\n",
    "sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_options))\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add( Conv2D(input_shape= INPUT_SHAPE, filters=64, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add( Conv2D(filters=64, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add( Conv2D(filters=128, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add( Conv2D(filters=128, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 6th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 7th Convolutional Layer\n",
    "model.add( Conv2D(filters=256, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 8th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 9th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 10th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add( MaxPooling2D(pool_size=(2,2), strides=(2,2)) )\n",
    "\n",
    "# 11th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 12th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# 13th Convolutional Layer\n",
    "model.add( Conv2D(filters=512, kernel_size=(3,3), strides = (1, 1), padding=\"same\") )\n",
    "model.add( Activation('relu') )\n",
    "\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "########################## Passing it to a Fully Connected layer ##########################\n",
    "model.add( Flatten() )\n",
    "\n",
    "K = INPUT_SHAPE[0] * INPUT_SHAPE[1] * INPUT_SHAPE[2]\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "model.add( Dense(4096, input_shape=( K, )) )\n",
    "model.add( Activation('relu') )\n",
    "# Add Dropout\n",
    "model.add( Dropout(0.4) )\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add( Dense(4096) )\n",
    "model.add( Activation('relu') )\n",
    "# Add Dropout\n",
    "model.add( Dropout(0.4) )\n",
    "\n",
    "# Output Layer\n",
    "model.add( Dense(2) )\n",
    "model.add( Activation('softmax') )\n",
    "          \n",
    "opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", # or binary_crossentropy\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, y, batch_size = 8, epochs = 10, validation_split = 0.1)  # batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch doesn't work well?\n",
    "Refer to this; https://stackoverflow.com/questions/37213388/keras-accuracy-does-not-change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
